import streamlit as st
import requests
from bs4 import BeautifulSoup
import csv
import io
import time
from urllib.parse import urljoin, urlparse
import pandas as pd
from datetime import datetime
import re
import numpy as np

# å®Ÿéš›ã®åˆ†æã‚¨ãƒ³ã‚¸ãƒ³
class AnswerGenkinkaAnalyzer:
    def __init__(self):
        self.base_url = "https://answer-genkinka.jp"
        self.seed_urls = [
            "https://answer-genkinka.jp/blog/",
            "https://answer-genkinka.jp/sitemap.xml"
        ]
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        })
        
    def extract_from_sitemap(self, sitemap_url):
        urls = []
        try:
            response = self.session.get(sitemap_url, timeout=10)
            soup = BeautifulSoup(response.content, 'xml')
            
            for loc in soup.find_all('loc'):
                url = loc.get_text()
                if self.is_article_page(url):
                    urls.append(url)
                    
        except Exception as e:
            st.warning(f"ã‚µã‚¤ãƒˆãƒãƒƒãƒ—å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            
        return list(set(urls))
    
    def is_article_page(self, url):
        if not url.startswith(self.base_url):
            return False
            
        path = urlparse(url).path
        
        exclude_patterns = [
            '/wp-admin', '/wp-content', '/wp-includes',
            '/feed', '/rss', '/sitemap', '/category', '/tag',
            '/author', '/search', '/page', '/privacy', '/terms'
        ]
        
        if any(pattern in path for pattern in exclude_patterns):
            return False
            
        article_patterns = [
            r'/blog/[^/]+/?$',
            r'/\d{4}/\d{2}/[^/]+/?$',
            r'/[^/]+/?$'
        ]
        
        return any(re.match(pattern, path) for pattern in article_patterns)
    
    def extract_links(self, soup, current_url):
        links = []
        
        for link in soup.find_all('a', href=True):
            href = link.get('href')
            if href:
                full_url = urljoin(current_url, href)
                if self.is_article_page(full_url):
                    links.append(full_url)
        
        for element in soup.find_all(attrs={'onclick': True}):
            onclick = element.get('onclick', '')
            if 'location.href' in onclick or 'window.open' in onclick:
                match = re.search(r"location\.href\s*=\s*['\"]([^'\"]+)['\"]", onclick)
                if not match:
                    match = re.search(r"window\.open\s*\(\s*['\"]([^'\"]+)['\"]", onclick)
                
                if match:
                    href = match.group(1)
                    full_url = urljoin(current_url, href)
                    if self.is_article_page(full_url):
                        links.append(full_url)
        
        return list(set(links))
    
    def analyze_page(self, url):
        try:
            response = self.session.get(url, timeout=10)
            soup = BeautifulSoup(response.content, 'html.parser')
            
            title_elem = soup.find('title')
            title = title_elem.get_text().strip() if title_elem else url
            
            content_selectors = [
                '.entry-content',
                '.post-content', 
                '.article-content',
                'article',
                'main'
            ]
            
            content_links = []
            for selector in content_selectors:
                content = soup.select_one(selector)
                if content:
                    content_links = self.extract_links(content, url)
                    break
            
            if not content_links:
                content_links = self.extract_links(soup, url)
            
            return {
                'url': url,
                'title': title,
                'outgoing_links': content_links,
                'status': 'success'
            }
            
        except Exception as e:
            return {
                'url': url,
                'title': f"å–å¾—ã‚¨ãƒ©ãƒ¼: {url}",
                'outgoing_links': [],
                'status': f'error: {str(e)}'
            }
    
    def analyze_site(self):
        st.info("answer-genkinka.jp ã®åˆ†æã‚’é–‹å§‹ã—ã¾ã™...")
        
        progress = st.progress(0)
        status = st.empty()
        
        status.text("URLåé›†ä¸­...")
        all_urls = set()
        
        for seed_url in self.seed_urls:
            if seed_url.endswith('.xml'):
                sitemap_urls = self.extract_from_sitemap(seed_url)
                all_urls.update(sitemap_urls)
                st.success(f"ã‚µã‚¤ãƒˆãƒãƒƒãƒ—ã‹ã‚‰ {len(sitemap_urls)} URL ã‚’å–å¾—")
            else:
                all_urls.add(seed_url)
        
        progress.progress(20)
        
        status.text(f"ãƒšãƒ¼ã‚¸åˆ†æä¸­... ({len(all_urls)} ãƒšãƒ¼ã‚¸)")
        
        results = []
        for i, url in enumerate(list(all_urls)[:20]):  # æœ€åˆã®20ãƒšãƒ¼ã‚¸ã«åˆ¶é™
            if i % 5 == 0:
                progress.progress(20 + int(60 * i / min(len(all_urls), 20)))
                status.text(f"åˆ†æä¸­... {i+1}/{min(len(all_urls), 20)}")
            
            result = self.analyze_page(url)
            results.append(result)
            time.sleep(0.5)
        
        progress.progress(80)
        
        status.text("è¢«ãƒªãƒ³ã‚¯æ•°è¨ˆç®—ä¸­...")
        
        link_counts = {}
        for result in results:
            url = result['url']
            link_counts[url] = link_counts.get(url, 0)
            
            for outgoing_url in result['outgoing_links']:
                link_counts[outgoing_url] = link_counts.get(outgoing_url, 0) + 1
        
        final_data = []
        for result in results:
            url = result['url']
            final_data.append({
                'ã‚¿ã‚¤ãƒˆãƒ«': result['title'],
                'URL': url,
                'è¢«ãƒªãƒ³ã‚¯æ•°': link_counts.get(url, 0),
                'ç™ºãƒªãƒ³ã‚¯æ•°': len(result['outgoing_links']),
                'ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹': result['status']
            })
        
        progress.progress(100)
        status.text("åˆ†æå®Œäº†ï¼")
        
        return final_data

# å„ã‚µã‚¤ãƒˆã®è¨­å®šæƒ…å ±
ANALYZER_CONFIGS = {
    "answer-genkinka.jp": {
        "name": "Answerç¾é‡‘åŒ–",
        "url": "https://answer-genkinka.jp/blog/",
        "status": "active",
        "last_analysis": None,
        "description": "ç¾é‡‘åŒ–ã‚µãƒ¼ãƒ“ã‚¹å°‚é–€ã‚µã‚¤ãƒˆ",
        "features": ["ãƒ–ãƒ­ã‚°è¨˜äº‹åˆ†æ", "å…¨è‡ªå‹•CSVå‡ºåŠ›"],
        "streamlit_url": "https://answer-analyzer.streamlit.app",
        "color": "#FF6B6B",
        "analyzer": AnswerGenkinkaAnalyzer
    },
    "arigataya.co.jp": {
        "name": "ã‚ã‚ŠãŒãŸã‚„", 
        "url": "https://arigataya.co.jp",
        "status": "planned",
        "last_analysis": None,
        "description": "onclickå¯¾å¿œãƒ»å…¨è‡ªå‹•ç‰ˆ",
        "features": ["onclickå¯¾å¿œ", "è‡ªå‹•ãƒªãƒ³ã‚¯æ¤œå‡º"],
        "streamlit_url": None,
        "color": "#4ECDC4",
        "analyzer": None
    },
    "kau-ru.co.jp": {
        "name": "ã‚«ã‚¦ãƒ¼ãƒ«",
        "url": "https://kau-ru.co.jp", 
        "status": "planned",
        "last_analysis": None,
        "description": "è¤‡æ•°ã‚µã‚¤ãƒˆå¯¾å¿œç‰ˆ",
        "features": ["WordPress API", "æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«é™¤å¤–"],
        "streamlit_url": None,
        "color": "#45B7D1",
        "analyzer": None
    },
    "crecaeru.co.jp": {
        "name": "ã‚¯ãƒ¬ã‹ãˆã‚‹",
        "url": "https://crecaeru.co.jp",
        "status": "planned", 
        "last_analysis": None,
        "description": "gnavé™¤å¤–å¯¾å¿œãƒ»onclickå¯¾å¿œç‰ˆ",
        "features": ["gnavé™¤å¤–", "onclickå¯¾å¿œ"],
        "streamlit_url": None,
        "color": "#96CEB4",
        "analyzer": None
    },
    "friendpay.jp": {
        "name": "ãƒ•ãƒ¬ãƒ³ãƒ‰ãƒšã‚¤",
        "url": "https://friendpay.jp",
        "status": "planned",
        "last_analysis": None, 
        "description": "ã‚µã‚¤ãƒˆåˆ¥é™¤å¤–ã‚»ãƒ¬ã‚¯ã‚¿ãƒ¼å¯¾å¿œ",
        "features": ["ã‚µã‚¤ãƒˆåˆ¥é™¤å¤–", "æœ€é©åŒ–åˆ†æ"],
        "streamlit_url": None,
        "color": "#FFEAA7",
        "analyzer": None
    },
    "kaitori-life.co.jp": {
        "name": "è²·å–LIFE",
        "url": "https://kaitori-life.co.jp",
        "status": "planned",
        "last_analysis": None,
        "description": "JINãƒ†ãƒ¼ãƒå°‚ç”¨æœ€é©åŒ–",
        "features": ["JINãƒ†ãƒ¼ãƒå¯¾å¿œ", "å°‚ç”¨ã‚»ãƒ¬ã‚¯ã‚¿ãƒ¼"],
        "streamlit_url": None,
        "color": "#FD79A8",
        "analyzer": None
    },
    "wallet-sos.jp": {
        "name": "ã‚¦ã‚©ãƒ¬ãƒƒãƒˆSOS",
        "url": "https://wallet-sos.jp",
        "status": "planned",
        "last_analysis": None,
        "description": "Seleniumç‰ˆï¼ˆCloudflareå¯¾ç­–ï¼‰",
        "features": ["Seleniumå¯¾å¿œ", "Cloudflareå¯¾ç­–"],
        "streamlit_url": None,
        "color": "#A29BFE",
        "analyzer": None
    },
    "wonderwall-invest.co.jp": {
        "name": "ãƒ¯ãƒ³ãƒ€ãƒ¼ã‚¦ã‚©ãƒ¼ãƒ«",
        "url": "https://wonderwall-invest.co.jp",
        "status": "planned",
        "last_analysis": None,
        "description": "secure-technologyå°‚ç”¨",
        "features": ["å°‚ç”¨æœ€é©åŒ–", "é«˜ç²¾åº¦åˆ†æ"],
        "streamlit_url": None,
        "color": "#6C5CE7",
        "analyzer": None
    },
    "fuyohin-kaishu.co.jp": {
        "name": "ä¸ç”¨å“å›å",
        "url": "https://fuyohin-kaishu.co.jp",
        "status": "planned",
        "last_analysis": None,
        "description": "ã‚«ãƒ†ã‚´ãƒªåˆ¥åˆ†æãƒ»ä¿®æ­£ç‰ˆ",
        "features": ["ã‚«ãƒ†ã‚´ãƒªåˆ¥åˆ†æ", "åŒ…æ‹¬çš„åé›†"],
        "streamlit_url": None,
        "color": "#00B894",
        "analyzer": None
    },
    "bic-gift.co.jp": {
        "name": "ãƒ“ãƒƒã‚¯ã‚®ãƒ•ãƒˆ",
        "url": "https://bic-gift.co.jp",
        "status": "planned",
        "last_analysis": None,
        "description": "SANGOãƒ†ãƒ¼ãƒå°‚ç”¨ãƒ»å…¨è‡ªå‹•ç‰ˆ",
        "features": ["SANGOãƒ†ãƒ¼ãƒå¯¾å¿œ", "å°‚ç”¨æŠ½å‡º"],
        "streamlit_url": None,
        "color": "#E17055",
        "analyzer": None
    },
    "flashpay.jp/famipay": {
        "name": "ãƒ•ã‚¡ãƒŸãƒšã‚¤",
        "url": "https://flashpay.jp/famipay/",
        "status": "planned",
        "last_analysis": None,
        "description": "/famipay/é…ä¸‹å°‚ç”¨",
        "features": ["é…ä¸‹é™å®šåˆ†æ", "é«˜ç²¾åº¦æŠ½å‡º"],
        "streamlit_url": None,
        "color": "#00CEC9",
        "analyzer": None
    },
    "flashpay.jp/media": {
        "name": "ãƒ•ãƒ©ãƒƒã‚·ãƒ¥ãƒšã‚¤",
        "url": "https://flashpay.jp/media/",
        "status": "planned",
        "last_analysis": None,
        "description": "/media/é…ä¸‹å°‚ç”¨",
        "features": ["ãƒ¡ãƒ‡ã‚£ã‚¢ç‰¹åŒ–", "åŠ¹ç‡åˆ†æ"],
        "streamlit_url": None,
        "color": "#74B9FF",
        "analyzer": None
    },
    "more-pay.jp": {
        "name": "ãƒ¢ã‚¢ãƒšã‚¤",
        "url": "https://more-pay.jp",
        "status": "planned",
        "last_analysis": None,
        "description": "æ”¹å–„ç‰ˆãƒ»åŒ…æ‹¬çš„åˆ†æ",
        "features": ["åŒ…æ‹¬åˆ†æ", "æ”¹å–„ç‰ˆã‚¨ãƒ³ã‚¸ãƒ³"],
        "streamlit_url": None,
        "color": "#FD79A8",
        "analyzer": None
    },
    "pay-ful.jp": {
        "name": "ãƒšã‚¤ãƒ•ãƒ«",
        "url": "https://pay-ful.jp/media/",
        "status": "planned", 
        "last_analysis": None,
        "description": "å€‹åˆ¥è¨˜äº‹ãƒšãƒ¼ã‚¸é‡è¦–",
        "features": ["è¨˜äº‹é‡è¦–", "ç²¾å¯†åˆ†æ"],
        "streamlit_url": None,
        "color": "#FDCB6E",
        "analyzer": None
    },
    "smart-pay.website": {
        "name": "ã‚¹ãƒãƒ¼ãƒˆãƒšã‚¤",
        "url": "https://smart-pay.website/media/",
        "status": "planned",
        "last_analysis": None,
        "description": "å¤§è¦æ¨¡ã‚µã‚¤ãƒˆå¯¾å¿œ",
        "features": ["å¤§è¦æ¨¡å¯¾å¿œ", "åŠ¹ç‡åŒ–ã‚¨ãƒ³ã‚¸ãƒ³"],
        "streamlit_url": None,
        "color": "#E84393",
        "analyzer": None
    },
    "xgift.jp": {
        "name": "ã‚¨ãƒƒã‚¯ã‚¹ã‚®ãƒ•ãƒˆ",
        "url": "https://xgift.jp/blog/",
        "status": "planned",
        "last_analysis": None,
        "description": "AFFINGERå¯¾å¿œ",
        "features": ["AFFINGERå¯¾å¿œ", "ãƒ†ãƒ¼ãƒæœ€é©åŒ–"],
        "streamlit_url": None,
        "color": "#00B894",
        "analyzer": None
    }
}

def main():
    st.set_page_config(
        page_title="å†…éƒ¨ãƒªãƒ³ã‚¯åˆ†æ çµ±æ‹¬ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ",
        page_icon="ğŸ›ï¸",
        layout="wide",
        initial_sidebar_state="expanded"
    )
    
    st.title("ğŸ›ï¸ å†…éƒ¨ãƒªãƒ³ã‚¯åˆ†æ çµ±æ‹¬ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ")
    st.markdown("**16ã‚µã‚¤ãƒˆå¯¾å¿œ - ä¸€å…ƒç®¡ç†ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰**")
    
    with st.sidebar:
        st.header("ğŸ“‹ ãƒ¡ãƒ‹ãƒ¥ãƒ¼")
        menu = st.radio(
            "æ©Ÿèƒ½ã‚’é¸æŠ",
            ["ğŸ  ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰", "ğŸ”— å€‹åˆ¥åˆ†æ", "ğŸ“Š çµ±è¨ˆãƒ»æ¯”è¼ƒ", "âš™ï¸ è¨­å®šç®¡ç†"],
            index=0
        )
        
        st.divider()
        st.markdown("**ğŸ“ˆ ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ³**")
        active_count = sum(1 for config in ANALYZER_CONFIGS.values() if config['status'] == 'active')
        st.metric("ç¨¼åƒä¸­", f"{active_count}/16ã‚µã‚¤ãƒˆ")
        
        st.divider()
        st.markdown("**ğŸ• æœ€çµ‚æ›´æ–°**")
        st.text(datetime.now().strftime("%Y-%m-%d %H:%M"))
    
    if menu == "ğŸ  ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰":
        show_dashboard()
    elif menu == "ğŸ”— å€‹åˆ¥åˆ†æ":
        show_individual_analysis()
    elif menu == "ğŸ“Š çµ±è¨ˆãƒ»æ¯”è¼ƒ":
        show_statistics()
    elif menu == "âš™ï¸ è¨­å®šç®¡ç†":
        show_settings()

def show_dashboard():
    st.header("ğŸ“Š ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“æ¦‚è¦")
    
    col1, col2, col3, col4 = st.columns(4)
    
    active_sites = [k for k, v in ANALYZER_CONFIGS.items() if v['status'] == 'active']
    planned_sites = [k for k, v in ANALYZER_CONFIGS.items() if v['status'] == 'planned']
    
    with col1:
        st.metric("ç·ã‚µã‚¤ãƒˆæ•°", len(ANALYZER_CONFIGS), delta="16ã‚µã‚¤ãƒˆ")
    with col2:
        st.metric("ç¨¼åƒä¸­", len(active_sites), delta=f"+{len(active_sites)}")
    with col3:
        st.metric("æº–å‚™ä¸­", len(planned_sites), delta=f"{len(planned_sites)}ã‚µã‚¤ãƒˆ")
    with col4:
        st.metric("æœ¬æ—¥ã®åˆ†æ", 0, delta="0å›")
    
    st.divider()
    
    st.subheader("ğŸ”— åˆ†æå¯¾è±¡ã‚µã‚¤ãƒˆä¸€è¦§")
    
    cols = st.columns(3)
    
    for i, (site_key, config) in enumerate(ANALYZER_CONFIGS.items()):
        col_idx = i % 3
        
        with cols[col_idx]:
            if config['status'] == 'active':
                status_color = "ğŸŸ¢"
                status_text = "ç¨¼åƒä¸­"
            elif config['status'] == 'planned':
                status_color = "ğŸŸ¡" 
                status_text = "æº–å‚™ä¸­"
            else:
                status_color = "ğŸ”´"
                status_text = "åœæ­¢ä¸­"
            
            with st.container():
                st.markdown(f"""
                <div style="
                    border: 2px solid {config['color']};
                    border-radius: 10px;
                    padding: 15px;
                    margin: 10px 0;
                    background: linear-gradient(135deg, {config['color']}15, {config['color']}05);
                ">
                    <h4 style="color: {config['color']}; margin: 0 0 10px 0;">
                        {status_color} {config['name']}
                    </h4>
                    <p style="margin: 5px 0; font-size: 0.9em;">
                        <strong>URL:</strong> {config['url'][:30]}...
                    </p>
                    <p style="margin: 5px 0; font-size: 0.9em;">
                        <strong>ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹:</strong> {status_text}
                    </p>
                    <p style="margin: 5px 0; font-size: 0.8em; color: #666;">
                        {config['description']}
                    </p>
                </div>
                """, unsafe_allow_html=True)
                
                if config['status'] == 'active':
                    if st.button(f"ğŸš€ {config['name']} åˆ†æå®Ÿè¡Œ", key=f"analyze_{site_key}"):
                        run_real_analysis(site_key, config)
                else:
                    st.button(f"â³ æº–å‚™ä¸­", disabled=True, key=f"disabled_{site_key}")

def run_real_analysis(site_key, config):
    """å®Ÿéš›ã®åˆ†æã‚’å®Ÿè¡Œ"""
    st.success(f"{config['name']} ã®åˆ†æã‚’é–‹å§‹ã—ã¾ã™...")
    
    if config.get('analyzer'):
        # å®Ÿéš›ã®åˆ†æã‚¨ãƒ³ã‚¸ãƒ³ã‚’ä½¿ç”¨
        analyzer = config['analyzer']()
        data = analyzer.analyze_site()
        
        if data:
            show_real_results(config['name'], data)
        else:
            st.error("åˆ†æã«å¤±æ•—ã—ã¾ã—ãŸ")
    else:
        st.warning(f"{config['name']} ã®åˆ†æã‚¨ãƒ³ã‚¸ãƒ³ã¯æº–å‚™ä¸­ã§ã™")

def show_real_results(site_name, data):
    """å®Ÿéš›ã®åˆ†æçµæœã‚’è¡¨ç¤º"""
    st.subheader(f"ğŸ“Š {site_name} åˆ†æçµæœ")
    
    df = pd.DataFrame(data)
    df_sorted = df.sort_values('è¢«ãƒªãƒ³ã‚¯æ•°', ascending=False)
    
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("ç·ãƒšãƒ¼ã‚¸æ•°", len(df))
    with col2:
        st.metric("ç·å†…éƒ¨ãƒªãƒ³ã‚¯æ•°", df['ç™ºãƒªãƒ³ã‚¯æ•°'].sum())
    with col3:
        st.metric("å­¤ç«‹ãƒšãƒ¼ã‚¸", len(df[df['è¢«ãƒªãƒ³ã‚¯æ•°'] == 0]))
    with col4:
        st.metric("æœ€å¤šè¢«ãƒªãƒ³ã‚¯", df['è¢«ãƒªãƒ³ã‚¯æ•°'].max())
    
    st.subheader("ğŸ“Š è¢«ãƒªãƒ³ã‚¯æ•°ãƒ©ãƒ³ã‚­ãƒ³ã‚°")
    
    top_10 = df_sorted.head(10)
    if not top_10.empty:
        chart_data = top_10.set_index('ã‚¿ã‚¤ãƒˆãƒ«')['è¢«ãƒªãƒ³ã‚¯æ•°']
        st.bar_chart(chart_data)
    
    st.subheader("ğŸ“‹ è©³ç´°ãƒ‡ãƒ¼ã‚¿")
    st.dataframe(df_sorted, use_container_width=True)
    
    csv_buffer = io.StringIO()
    df_sorted.to_csv(csv_buffer, index=False, encoding='utf-8-sig')
    csv_data = csv_buffer.getvalue()
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"{site_name}_analysis_{timestamp}.csv"
    
    st.download_button(
        "ğŸ“¥ CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
        csv_data,
        filename,
        "text/csv",
        help="è¢«ãƒªãƒ³ã‚¯æ•°é †ã§ã‚½ãƒ¼ãƒˆã•ã‚ŒãŸè©³ç´°ãƒ¬ãƒãƒ¼ãƒˆ"
    )

def show_individual_analysis():
    st.header("ğŸ”— å€‹åˆ¥ã‚µã‚¤ãƒˆåˆ†æ")
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        selected_site = st.selectbox(
            "åˆ†æå¯¾è±¡ã‚µã‚¤ãƒˆã‚’é¸æŠ",
            options=list(ANALYZER_CONFIGS.keys()),
            format_func=lambda x: f"{ANALYZER_CONFIGS[x]['name']} ({x})"
        )
    
    with col2:
        st.markdown("**é¸æŠã‚µã‚¤ãƒˆæƒ…å ±**")
        config = ANALYZER_CONFIGS[selected_site]
        st.info(f"""
        **åç§°:** {config['name']}  
        **URL:** {config['url']}  
        **ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹:** {config['status']}  
        **èª¬æ˜:** {config['description']}
        """)
    
    st.subheader(f"ğŸ¯ {config['name']} ã®å°‚ç”¨æ©Ÿèƒ½")
    
    feature_cols = st.columns(len(config['features']))
    for i, feature in enumerate(config['features']):
        with feature_cols[i]:
            st.markdown(f"""
            <div style="
                background: {config['color']}20;
                border: 1px solid {config['color']};
                border-radius: 5px;
                padding: 10px;
                text-align: center;
                margin: 5px;
            ">
                <strong>{feature}</strong>
            </div>
            """, unsafe_allow_html=True)
    
    st.divider()
    
    st.subheader("ğŸš€ åˆ†æå®Ÿè¡Œ")
    
    if config['status'] == 'active':
        url_input = st.text_input(
            "åˆ†æURLï¼ˆã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºå¯èƒ½ï¼‰",
            value=config['url'],
            help="ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆURLä»¥å¤–ã‚‚åˆ†æå¯èƒ½ã§ã™"
        )
        
        col1, col2, col3 = st.columns([2, 1, 1])
        
        with col1:
            if st.button(f"ğŸ” {config['name']} åˆ†æé–‹å§‹", type="primary"):
                run_real_analysis(selected_site, config)
        
        with col2:
            if st.button("ğŸ“Š å±¥æ­´è¡¨ç¤º"):
                st.info("åˆ†æå±¥æ­´æ©Ÿèƒ½ã¯æº–å‚™ä¸­ã§ã™")
        
        with col3:
            if st.button("âš™ï¸ è¨­å®š"):
                st.info("å€‹åˆ¥è¨­å®šæ©Ÿèƒ½ã¯æº–å‚™ä¸­ã§ã™")
    
    else:
        st.warning(f"{config['name']} ã¯ã¾ã æº–å‚™ä¸­ã§ã™ã€‚Streamlitç‰ˆã¸ã®ç§»è¡Œä½œæ¥­ã‚’é€²ã‚ã¦ã„ã¾ã™ã€‚")
        
        st.markdown("**ç§»è¡ŒçŠ¶æ³:**")
        progress = st.progress(0)
        st.text("CustomTkinter â†’ Streamlit å¤‰æ›ä½œæ¥­ä¸­...")

def show_statistics():
    st.header("ğŸ“Š çµ±è¨ˆãƒ»æ¯”è¼ƒåˆ†æ")
    
    st.info("çµ±è¨ˆãƒ»æ¯”è¼ƒæ©Ÿèƒ½ã¯å„ã‚µã‚¤ãƒˆã®StreamlitåŒ–å®Œäº†å¾Œã«å®Ÿè£…äºˆå®šã§ã™")
    
    st.subheader("ğŸ”® å®Ÿè£…äºˆå®šæ©Ÿèƒ½")
    
    features = [
        "ğŸ“ˆ å…¨ã‚µã‚¤ãƒˆæ¨ªæ–­çµ±è¨ˆ",
        "ğŸ”„ ã‚µã‚¤ãƒˆé–“æ¯”è¼ƒåˆ†æ", 
        "ğŸ“… æ™‚ç³»åˆ—ãƒˆãƒ¬ãƒ³ãƒ‰",
        "ğŸ¯ SEOæ”¹å–„ææ¡ˆ",
        "ğŸ“Š çµ±åˆãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ",
        "âš¡ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç›£è¦–"
    ]
    
    cols = st.columns(2)
    for i, feature in enumerate(features):
        with cols[i % 2]:
            st.markdown(f"- {feature}")

def show_settings():
    st.header("âš™ï¸ è¨­å®šç®¡ç†")
    
    st.subheader("ğŸ”§ ã‚·ã‚¹ãƒ†ãƒ è¨­å®š")
    
    with st.expander("å…¨èˆ¬è¨­å®š", expanded=True):
        auto_analysis = st.checkbox("è‡ªå‹•åˆ†æã‚’æœ‰åŠ¹åŒ–", value=False)
        analysis_interval = st.selectbox("åˆ†æé–“éš”", ["1æ™‚é–“", "6æ™‚é–“", "12æ™‚é–“", "24æ™‚é–“"])
        max_concurrent = st.slider("åŒæ™‚å®Ÿè¡Œæ•°", 1, 5, 2)
    
    with st.expander("é€šçŸ¥è¨­å®š"):
        email_notify = st.checkbox("ãƒ¡ãƒ¼ãƒ«é€šçŸ¥", value=False)
        slack_notify = st.checkbox("Slacké€šçŸ¥", value=False)
        if email_notify:
            email = st.text_input("é€šçŸ¥å…ˆãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹")
        if slack_notify:
            webhook = st.text_input("Slack Webhook URL")
    
    with st.expander("ã‚µã‚¤ãƒˆåˆ¥è¨­å®š"):
        for site_key, config in ANALYZER_CONFIGS.items():
            st.markdown(f"**{config['name']} ({site_key})**")
            
            col1, col2, col3 = st.columns(3)
            with col1:
                enabled = st.checkbox("æœ‰åŠ¹", value=config['status']=='active', key=f"enable_{site_key}")
            with col2:
                priority = st.selectbox("å„ªå…ˆåº¦", ["é«˜", "ä¸­", "ä½"], key=f"priority_{site_key}")
            with col3:
                timeout = st.number_input("ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ(ç§’)", 10, 300, 60, key=f"timeout_{site_key}")
            
            st.divider()
    
    if st.button("ğŸ’¾ è¨­å®šã‚’ä¿å­˜", type="primary"):
        st.success("è¨­å®šã‚’ä¿å­˜ã—ã¾ã—ãŸï¼")
        st.balloons()

if __name__ == "__main__":
    main()
