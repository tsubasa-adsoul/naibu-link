#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
å†…éƒ¨ãƒªãƒ³ã‚¯æ§‹é€ åˆ†æãƒ„ãƒ¼ãƒ«ï¼ˆCSVèª­è¾¼å°‚ç”¨ãƒ»å®Œå…¨ç‰ˆï¼‰
- ãƒ”ãƒ©ãƒ¼ãƒšãƒ¼ã‚¸ / ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ï¼ˆã‚¢ãƒ³ã‚«ãƒ¼ï¼‰ / å­¤ç«‹è¨˜äº‹ã‚’å…¨ä»¶å‡ºåŠ›ï¼ˆHTMLè¡¨ & ç”»é¢ãƒ†ã‚­ã‚¹ãƒˆï¼‰
- ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å›³ï¼ˆé™çš„ï¼šæ•£å¸ƒãƒ»çŸ­ç¸®ãƒ©ãƒ™ãƒ«ã€ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ï¼špyvisï¼‰
- ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ã¯ä¸Šä½ã‚¿ãƒ¼ã‚²ãƒƒãƒˆæŠ½å‡ºï¼‹ã‚¨ãƒƒã‚¸é›†ç´„ï¼‹è»½é‡ç‰©ç† â†’ é€Ÿã„
- æ—¢å®šã§ãƒ–ãƒ©ã‚¦ã‚¶è‡ªå‹•èµ·å‹• OFFï¼ˆç”»é¢ã®ã‚¹ã‚¤ãƒƒãƒã§ONã«åˆ‡æ›¿å¯ï¼‰
- ãƒ­ã‚°ã¯ ./logs/ ã«ä¿å­˜ã€HTMLã¯ ./reports/ ã¨ ./network_exports/ ã«ä¿å­˜
"""

import os
import sys
import csv
import math
import json
import webbrowser
import logging
from logging.handlers import RotatingFileHandler
from pathlib import Path
from collections import Counter
from datetime import datetime
from urllib.parse import urlparse

# ---------------- ãƒ­ã‚° ----------------
LOG_DIR = Path.cwd() / "logs"
LOG_DIR.mkdir(exist_ok=True)
LOG_FILE = LOG_DIR / f"link_tool_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log"

logger = logging.getLogger("link_tool")
logger.setLevel(logging.DEBUG)
if not logger.handlers:
    ch = logging.StreamHandler(sys.stdout)
    ch.setLevel(logging.DEBUG)
    ch.setFormatter(logging.Formatter("%(asctime)s [%(levelname)s] %(message)s"))
    fh = RotatingFileHandler(LOG_FILE, maxBytes=5*1024*1024, backupCount=3, encoding="utf-8")
    fh.setLevel(logging.DEBUG)
    fh.setFormatter(logging.Formatter("%(asctime)s [%(levelname)s] %(message)s"))
    logger.addHandler(ch)
    logger.addHandler(fh)

def install_global_exception_hooks(root=None):
    def excepthook(exctype, value, tb):
        logger.exception("UNCAUGHT", exc_info=(exctype, value, tb))
    sys.excepthook = excepthook
    if root is not None:
        def _tk_err(exc, val, tb):
            logger.exception("TK CALLBACK", exc_info=(exc, val, tb))
        root.report_callback_exception = _tk_err  # type: ignore

# ---------------- Matplotlibï¼ˆæ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆï¼‰ ----------------
import matplotlib
matplotlib.use('TkAgg')
import matplotlib.pyplot as plt
for f in ['Yu Gothic', 'Meiryo', 'Noto Sans CJK JP', 'MS Gothic', 'DejaVu Sans']:
    try:
        plt.rcParams['font.family'] = f
        logger.info(f"Using font family: {f}")
        break
    except Exception:
        pass
plt.rcParams['axes.unicode_minus'] = False
from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg

# ---------------- GUI/Data ----------------
import customtkinter as ctk
import pandas as pd

# ---------------- PyVisï¼ˆä»»æ„ï¼‰ ----------------
try:
    from pyvis.network import Network
    HAS_PYVIS = True
    logger.info("PyVis imported successfully")
except Exception as e:
    logger.warning(f"pyvis import failed: {e}")
    HAS_PYVIS = False
    Network = None

ctk.set_appearance_mode("light")
ctk.set_default_color_theme("blue")

EXPECTED_COLUMNS = [
    'A_ç•ªå·',
    'B_ãƒšãƒ¼ã‚¸ã‚¿ã‚¤ãƒˆãƒ«',
    'C_URL',
    'D_è¢«ãƒªãƒ³ã‚¯å…ƒãƒšãƒ¼ã‚¸ã‚¿ã‚¤ãƒˆãƒ«',
    'E_è¢«ãƒªãƒ³ã‚¯å…ƒãƒšãƒ¼ã‚¸URL',
    'F_è¢«ãƒªãƒ³ã‚¯å…ƒãƒšãƒ¼ã‚¸ã‚¢ãƒ³ã‚«ãƒ¼ãƒ†ã‚­ã‚¹ãƒˆ'
]

def safe_str(s): return s if isinstance(s, str) else ""

def normalize_url(u, default_scheme="https", base_domain=None):
    if not isinstance(u, str) or not u.strip():
        return ""
    u = u.strip()
    from urllib.parse import urlparse, urlunparse
    p = urlparse(u)

    if not p.netloc and base_domain:
        path = u if u.startswith("/") else f"/{u}"
        u = f"{default_scheme}://{base_domain}{path}"
        p = urlparse(u)
    elif not p.netloc:
        return u

    scheme = p.scheme or default_scheme
    netloc = p.netloc.lower()
    if netloc.startswith("www."): netloc = netloc[4:]
    path = p.path or "/"
    return urlunparse((scheme, netloc, path, p.params, p.query, ""))

class App:
    def __init__(self):
        self.root = ctk.CTk()
        install_global_exception_hooks(self.root)

        self.root.title("ğŸ”— å†…éƒ¨ãƒªãƒ³ã‚¯æ§‹é€ åˆ†æãƒ„ãƒ¼ãƒ«ï¼ˆCSVèª­è¾¼å°‚ç”¨ãƒ»å®Œå…¨ç‰ˆï¼‰")
        self.root.geometry("1400x900")

        self.df = None
        self.site_name = "Unknown Site"
        self.site_domain = None

        self.last_html = None
        self.auto_open = ctk.BooleanVar(value=False)  # â˜… æ—¢å®šã§è‡ªå‹•ãƒ–ãƒ©ã‚¦ã‚¶OFF

        self._build_ui()

    def _build_ui(self):
        top = ctk.CTkFrame(self.root)
        top.pack(fill="x", padx=8, pady=8)

        ctk.CTkButton(top, text="ğŸ“‚ CSVã‚’é–‹ã", command=self.load_csv).pack(side="left", padx=6)
        self.btn_pillar = ctk.CTkButton(top, text="ğŸ›ï¸ ãƒ”ãƒ©ãƒ¼ãƒšãƒ¼ã‚¸", command=self.do_pillar, state="disabled")
        self.btn_pillar.pack(side="left", padx=6)
        self.btn_cluster = ctk.CTkButton(top, text="ğŸ§© ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼", command=self.do_cluster, state="disabled")
        self.btn_cluster.pack(side="left", padx=6)
        self.btn_isolated = ctk.CTkButton(top, text="ğŸ§­ å­¤ç«‹è¨˜äº‹", command=self.do_isolated, state="disabled")
        self.btn_isolated.pack(side="left", padx=6)
        self.btn_static = ctk.CTkButton(top, text="ğŸ“ˆ ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ï¼ˆé™çš„ï¼‰", command=self.show_static_network, state="disabled")
        self.btn_static.pack(side="left", padx=6)
        self.btn_inter = ctk.CTkButton(top, text="ğŸŒ ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ï¼ˆãƒ–ãƒ©ã‚¦ã‚¶ï¼‰", command=self.show_interactive_network, state="disabled")
        self.btn_inter.pack(side="left", padx=6)

        self.chk_open = ctk.CTkSwitch(top, text="è‡ªå‹•ã§ãƒ–ãƒ©ã‚¦ã‚¶ã‚’é–‹ã", variable=self.auto_open)
        self.chk_open.pack(side="left", padx=12)

        ctk.CTkButton(top, text="ğŸŒ æœ€å¾Œã®ãƒ¬ãƒãƒ¼ãƒˆã‚’é–‹ã", command=self.open_last_html).pack(side="left", padx=6)
        ctk.CTkButton(top, text="ğŸ“ æœ€å¾Œã®ãƒ¬ãƒãƒ¼ãƒˆã‚’åˆ¥åä¿å­˜", command=self.save_last_html).pack(side="left", padx=6)
        ctk.CTkButton(top, text="ğŸ“œ ãƒ­ã‚°ãƒ•ã‚©ãƒ«ãƒ€", command=self.open_logs).pack(side="left", padx=6)

        self.lbl_status = ctk.CTkLabel(top, text=f"ãƒ­ã‚°: {LOG_FILE.name}")
        self.lbl_status.pack(side="right", padx=8)

        main = ctk.CTkFrame(self.root)
        main.pack(fill="both", expand=True, padx=8, pady=4)

        left = ctk.CTkFrame(main, width=300)
        left.pack(side="left", fill="y", padx=6, pady=6)
        left.pack_propagate(False)
        self.lbl_file = ctk.CTkLabel(left, text="CSVæœªèª­è¾¼", anchor="w", justify="left")
        self.lbl_file.pack(fill="x", padx=8, pady=8)

        right = ctk.CTkFrame(main)
        right.pack(side="left", fill="both", expand=True, padx=6, pady=6)
        self.txt = ctk.CTkTextbox(right, wrap="none")
        self.txt.pack(fill="both", expand=True)
        xbar = ctk.CTkScrollbar(right, orientation="horizontal", command=self.txt.xview)
        xbar.pack(side="bottom", fill="x")
        ybar = ctk.CTkScrollbar(right, orientation="vertical", command=self.txt.yview)
        ybar.pack(side="right", fill="y")
        self.txt.configure(xscrollcommand=xbar.set, yscrollcommand=ybar.set)

    def _enable_analysis(self, on=True):
        for b in [self.btn_pillar, self.btn_cluster, self.btn_isolated, self.btn_static, self.btn_inter]:
            b.configure(state="normal" if on else "disabled")

    def _print(self, s: str, clear=False):
        if clear:
            self.txt.delete("1.0", "end")
        self.txt.insert("end", s)
        self.txt.see("end")

    def open_logs(self):
        try:
            if os.name == "nt": os.startfile(LOG_DIR)
            else: webbrowser.open(LOG_DIR.as_posix())
        except Exception:
            logger.exception("open_logs failed")

    # ------------ CSV ------------
    def load_csv(self):
        from tkinter import filedialog, messagebox
        path = filedialog.askopenfilename(
            title="CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠ",
            filetypes=[("CSV files", "*.csv")],
            initialdir=os.getcwd()
        )
        if not path:
            return
        try:
            logger.info(f"Loading CSV: {path}")
            df = pd.read_csv(path, encoding="utf-8-sig").fillna("")
            if not all(col in df.columns for col in EXPECTED_COLUMNS):
                messagebox.showerror("ã‚¨ãƒ©ãƒ¼", f"CSVåˆ—ãŒä¸è¶³ï¼š\nå¿…è¦: {EXPECTED_COLUMNS}\nå®Ÿéš›: {list(df.columns)}")
                return
            self.df = df

            fname = os.path.basename(path)
            if   'kau-ru'       in fname: self.site_name = "ã‚«ã‚¦ãƒ¼ãƒ«"
            elif 'kaitori-life' in fname: self.site_name = "è²·å–LIFE"
            elif 'friendpay'    in fname: self.site_name = "ãƒ•ãƒ¬ãƒ³ãƒ‰ãƒšã‚¤"
            elif 'kurekaeru' in fname or 'crecaeru' in fname: self.site_name = "ã‚¯ãƒ¬ã‹ãˆã‚‹"
            else: self.site_name = "Unknown Site"

            domains = []
            for u in self.df['C_URL'].tolist():
                if isinstance(u, str) and u:
                    d = urlparse(u).netloc.lower()
                    if d.startswith("www."): d = d[4:]
                    if d: domains.append(d)
            self.site_domain = Counter(domains).most_common(1)[0][0] if domains else None

            def _norm(u): return normalize_url(u, base_domain=self.site_domain)
            self.df['C_URL'] = self.df['C_URL'].apply(_norm)
            self.df['E_è¢«ãƒªãƒ³ã‚¯å…ƒãƒšãƒ¼ã‚¸URL'] = self.df['E_è¢«ãƒªãƒ³ã‚¯å…ƒãƒšãƒ¼ã‚¸URL'].apply(_norm)

            self.lbl_file.configure(text=f"èª­è¾¼: {fname}ï¼ˆ{len(self.df)}è¡Œï¼‰\nãƒ‰ãƒ¡ã‚¤ãƒ³: {self.site_domain or 'ä¸æ˜'}")
            self._enable_analysis(True)
            self._print(f"CSVèª­è¾¼å®Œäº†: {fname}\nã‚µã‚¤ãƒˆ: {self.site_name}\n\n", clear=True)
        except Exception as e:
            logger.exception("load_csv failed")
            from tkinter import messagebox
            messagebox.showerror("èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼", f"{e}")

    # ------------ é›†è¨ˆãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ ------------
    def _pages_set(self):
        if self.df is None:
            return pd.DataFrame(columns=['B_ãƒšãƒ¼ã‚¸ã‚¿ã‚¤ãƒˆãƒ«', 'C_URL']).drop_duplicates()
        return self.df[['B_ãƒšãƒ¼ã‚¸ã‚¿ã‚¤ãƒˆãƒ«', 'C_URL']].drop_duplicates()

    def _inbound_counts(self):
        if self.df is None:
            return pd.Series(dtype=int)
        has_src = (self.df['D_è¢«ãƒªãƒ³ã‚¯å…ƒãƒšãƒ¼ã‚¸ã‚¿ã‚¤ãƒˆãƒ«'].astype(str) != "") & (self.df['E_è¢«ãƒªãƒ³ã‚¯å…ƒãƒšãƒ¼ã‚¸URL'].astype(str) != "")
        inbound = self.df[has_src & (self.df['C_URL'].astype(str) != "")]
        return inbound.groupby('C_URL').size()

    # ------------ HTMLå‡ºåŠ› ------------
    def _write_html_table(self, title: str, columns, rows, out_path: Path):
        out_path.parent.mkdir(exist_ok=True, parents=True)
        def esc(x):
            return (str(x).replace("&", "&amp;").replace("<", "&lt;").replace(">", "&gt;"))
        html = [
            "<!doctype html><meta charset='utf-8'>",
            f"<title>{esc(title)}</title>",
            "<style>body{font-family: Arial, 'Yu Gothic', Meiryo, sans-serif; padding:16px;} table{border-collapse:collapse; width:100%;} th,td{border:1px solid #ddd; padding:6px; font-size:14px;} th{position:sticky;top:0;background:#f7f7f7;} tr:nth-child(even){background:#fafafa;} a{color:#1565c0; text-decoration:none;} a:hover{text-decoration:underline;}</style>",
            f"<h2>{esc(title)}</h2>",
            "<table><thead><tr>"
        ]
        for c in columns:
            html.append(f"<th>{esc(c)}</th>")
        html.append("</tr></thead><tbody>")
        for row in rows:
            html.append("<tr>")
            for i, cell in enumerate(row):
                val = esc(cell)
                header = columns[i]
                if "URL" in header.upper() or header.endswith("URL"):
                    if val and (val.startswith("http://") or val.startswith("https://")):
                        val = f"<a href='{val}' target='_blank' rel='noopener'>{val}</a>"
                html.append(f"<td>{val}</td>")
            html.append("</tr>")
        html.append("</tbody></table>")
        with open(out_path, "w", encoding="utf-8") as f:
            f.write("".join(html))
        return out_path

    def _maybe_open(self, path: Path):
        if not self.auto_open.get():
            return
        try:
            if os.name == "nt": os.startfile(path)
            else: webbrowser.open(path.as_posix())
        except Exception:
            webbrowser.open(path.as_posix())

    # ------------ ãƒ”ãƒ©ãƒ¼ãƒšãƒ¼ã‚¸ ------------
    def do_pillar(self):
        if self.df is None: return
        self._print("â–¶ ãƒ”ãƒ©ãƒ¼ãƒšãƒ¼ã‚¸åˆ†æã‚’é–‹å§‹â€¦\n", clear=True)
        try:
            pages = self._pages_set().copy()
            inbound = self._inbound_counts()
            pages['è¢«ãƒªãƒ³ã‚¯æ•°'] = pages['C_URL'].map(inbound).fillna(0).astype(int)
            pages.sort_values(['è¢«ãƒªãƒ³ã‚¯æ•°','B_ãƒšãƒ¼ã‚¸ã‚¿ã‚¤ãƒˆãƒ«'], ascending=[False, True], inplace=True)

            lines = [f"[{i}] {safe_str(r['B_ãƒšãƒ¼ã‚¸ã‚¿ã‚¤ãƒˆãƒ«'])}  ({int(r['è¢«ãƒªãƒ³ã‚¯æ•°'])})\n    {safe_str(r['C_URL'])}\n"
                     for i, (_, r) in enumerate(pages.iterrows(), 1)]
            self._print("".join(lines))

            out_dir = Path.cwd()/ "reports"
            out = out_dir / f"pillar_{datetime.now().strftime('%Y%m%d_%H%M%S')}.html"
            rows = [[i, safe_str(r['B_ãƒšãƒ¼ã‚¸ã‚¿ã‚¤ãƒˆãƒ«']), safe_str(r['C_URL']), int(r['è¢«ãƒªãƒ³ã‚¯æ•°'])]
                    for i, (_, r) in enumerate(pages.iterrows(), 1)]
            self.last_html = self._write_html_table(f"{self.site_name} ãƒ”ãƒ©ãƒ¼ãƒšãƒ¼ã‚¸ï¼ˆå…¨ä»¶ï¼‰",
                                                    ["#", "ãƒšãƒ¼ã‚¸ã‚¿ã‚¤ãƒˆãƒ«", "URL", "è¢«ãƒªãƒ³ã‚¯æ•°"],
                                                    rows, out)
            self._print(f"\nHTMLãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆã—ã¾ã—ãŸ: {self.last_html}\nï¼ˆè‡ªå‹•ã‚ªãƒ¼ãƒ—ãƒ³: { 'ON' if self.auto_open.get() else 'OFF' }ï¼‰\n")
            self._maybe_open(self.last_html)
        except Exception as e:
            logger.exception("do_pillar failed")
            self._print(f"\n[ã‚¨ãƒ©ãƒ¼] {e}\n")

    # ------------ ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ï¼ˆã‚¢ãƒ³ã‚«ãƒ¼ï¼‰ ------------
    def do_cluster(self):
        if self.df is None: return
        self._print("â–¶ ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ï¼ˆã‚¢ãƒ³ã‚«ãƒ¼ãƒ†ã‚­ã‚¹ãƒˆï¼‰åˆ†æã‚’é–‹å§‹â€¦\n", clear=True)
        try:
            anchors = self.df[(self.df['F_è¢«ãƒªãƒ³ã‚¯å…ƒãƒšãƒ¼ã‚¸ã‚¢ãƒ³ã‚«ãƒ¼ãƒ†ã‚­ã‚¹ãƒˆ'].astype(str) != "")]
            ac = Counter(anchors['F_è¢«ãƒªãƒ³ã‚¯å…ƒãƒšãƒ¼ã‚¸ã‚¢ãƒ³ã‚«ãƒ¼ãƒ†ã‚­ã‚¹ãƒˆ']) if len(anchors) else Counter()
            total = sum(ac.values())
            hhi = sum((c/total)**2 for c in ac.values()) if total else 0.0
            diversity = 1 - hhi
            self._print(f"ãƒ¦ãƒ‹ãƒ¼ã‚¯ã‚¢ãƒ³ã‚«ãƒ¼: {len(ac)} / å¤šæ§˜æ€§(1=é«˜): {diversity:.3f}\n\n")
            for i, (a, c) in enumerate(ac.most_common(), 1):
                self._print(f"[{i}] {safe_str(a)}  ({c})\n")

            out_dir = Path.cwd()/ "reports"
            out = out_dir / f"anchors_{datetime.now().strftime('%Y%m%d_%H%M%S')}.html"
            rows = [[i, a, c] for i, (a, c) in enumerate(ac.most_common(), 1)]
            self.last_html = self._write_html_table(f"{self.site_name} ã‚¢ãƒ³ã‚«ãƒ¼ãƒ†ã‚­ã‚¹ãƒˆé »åº¦ï¼ˆå…¨ä»¶ï¼‰",
                                                    ["#", "ã‚¢ãƒ³ã‚«ãƒ¼ãƒ†ã‚­ã‚¹ãƒˆ", "å›æ•°"], rows, out)
            self._print(f"\nHTMLãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆã—ã¾ã—ãŸ: {self.last_html}\nï¼ˆè‡ªå‹•ã‚ªãƒ¼ãƒ—ãƒ³: { 'ON' if self.auto_open.get() else 'OFF' }ï¼‰\n")
            self._maybe_open(self.last_html)
        except Exception as e:
            logger.exception("do_cluster failed")
            self._print(f"\n[ã‚¨ãƒ©ãƒ¼] {e}\n")

    # ------------ å­¤ç«‹è¨˜äº‹ ------------
    def do_isolated(self):
        if self.df is None: return
        self._print("â–¶ å­¤ç«‹è¨˜äº‹åˆ†æã‚’é–‹å§‹â€¦\n", clear=True)
        try:
            pages = self._pages_set().copy()
            inbound = self._inbound_counts()
            pages['è¢«ãƒªãƒ³ã‚¯æ•°'] = pages['C_URL'].map(inbound).fillna(0).astype(int)
            isolated = pages[pages['è¢«ãƒªãƒ³ã‚¯æ•°'] == 0].copy()
            isolated.sort_values('B_ãƒšãƒ¼ã‚¸ã‚¿ã‚¤ãƒˆãƒ«', inplace=True)

            if isolated.empty:
                self._print("å­¤ç«‹è¨˜äº‹ã¯ 0 ä»¶ã§ã—ãŸã€‚\n")
            else:
                self._print(f"å­¤ç«‹è¨˜äº‹: {len(isolated)} ä»¶\n\n")
                for i, (_, r) in enumerate(isolated.iterrows(), 1):
                    self._print(f"[{i}] {safe_str(r['B_ãƒšãƒ¼ã‚¸ã‚¿ã‚¤ãƒˆãƒ«'])}\n    {safe_str(r['C_URL'])}\n")

                out_dir = Path.cwd()/ "reports"
                out = out_dir / f"isolated_{datetime.now().strftime('%Y%m%d_%H%M%S')}.html"
                rows = [[i, safe_str(r['B_ãƒšãƒ¼ã‚¸ã‚¿ã‚¤ãƒˆãƒ«']), safe_str(r['C_URL'])]
                        for i, (_, r) in enumerate(isolated.iterrows(), 1)]
                self.last_html = self._write_html_table(f"{self.site_name} å­¤ç«‹è¨˜äº‹ï¼ˆå…¨ä»¶ï¼‰",
                                                        ["#", "ãƒšãƒ¼ã‚¸ã‚¿ã‚¤ãƒˆãƒ«", "URL"], rows, out)
                self._print(f"\nHTMLãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆã—ã¾ã—ãŸ: {self.last_html}\nï¼ˆè‡ªå‹•ã‚ªãƒ¼ãƒ—ãƒ³: { 'ON' if self.auto_open.get() else 'OFF' }ï¼‰\n")
                self._maybe_open(self.last_html)
        except Exception as e:
            logger.exception("do_isolated failed")
            self._print(f"\n[ã‚¨ãƒ©ãƒ¼] {e}\n")

    # ------------ é™çš„ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ï¼ˆåˆ¥ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ï¼‰ ------------
    def show_static_network(self):
        if self.df is None: return
        try:
            import tkinter as tk
            pages = self._pages_set().copy()
            inbound = self._inbound_counts()
            pages['è¢«ãƒªãƒ³ã‚¯æ•°'] = pages['C_URL'].map(inbound).fillna(0).astype(int)
            pages.sort_values('è¢«ãƒªãƒ³ã‚¯æ•°', ascending=False, inplace=True)
            top = pages.head(20)

            win = tk.Toplevel(self.root)
            win.title("ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ç°¡æ˜“å›³ï¼ˆæ•£å¸ƒãƒ»é™çš„ï¼‰")
            win.geometry("980x720")

            fig, ax = plt.subplots(figsize=(9.8, 7.2))
            xs = list(range(len(top)))
            ys = top['è¢«ãƒªãƒ³ã‚¯æ•°'].tolist()
            sizes = [max(80, v*28) for v in ys]
            ax.scatter(xs, ys, s=sizes, alpha=0.75)

            def short(s, n=24):
                s = safe_str(s)
                return (s[:n] + "â€¦") if len(s) > n else s

            for i, (_, r) in enumerate(top.iterrows()):
                ax.annotate(
                    short(r['B_ãƒšãƒ¼ã‚¸ã‚¿ã‚¤ãƒˆãƒ«']),
                    (xs[i], ys[i]),
                    xytext=(0, 12), textcoords="offset points",
                    ha='center', va='bottom', fontsize=9, clip_on=True,
                    bbox=dict(boxstyle="round,pad=0.2", fc="white", ec="0.8", alpha=0.85)
                )

            ax.set_title('è¢«ãƒªãƒ³ã‚¯ä¸Šä½ï¼ˆæ•£å¸ƒå›³ãƒ»çŸ­ç¸®ãƒ©ãƒ™ãƒ«ï¼‰')
            ax.set_xlabel('ãƒšãƒ¼ã‚¸ï¼ˆä¸Šä½é †ï¼‰'); ax.set_ylabel('è¢«ãƒªãƒ³ã‚¯æ•°')
            ax.grid(True, alpha=0.25); fig.tight_layout()

            canv = FigureCanvasTkAgg(fig, master=win)
            canv.draw()
            canv.get_tk_widget().pack(fill="both", expand=True)
        except Exception as e:
            logger.exception("show_static_network failed")
            self._print(f"\n[æç”»ã‚¨ãƒ©ãƒ¼] {e}\n")

    # ------------ ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ï¼ˆpyvisï¼‰ â˜…ä¿®æ­£éƒ¨åˆ† ------------
    def show_interactive_network(self):
        from tkinter import messagebox
        if self.df is None:
            messagebox.showerror("ã‚¨ãƒ©ãƒ¼", "CSVã‚’èª­ã¿è¾¼ã‚“ã§ãã ã•ã„ã€‚")
            return
        if not HAS_PYVIS:
            messagebox.showerror("ã‚¨ãƒ©ãƒ¼", "pyvis ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚`pip install pyvis` ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
            return
        try:
            self._print("â–¶ ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’ç”Ÿæˆä¸­â€¦\n", clear=True)
            
            edges_df = self.df[
                (self.df['E_è¢«ãƒªãƒ³ã‚¯å…ƒãƒšãƒ¼ã‚¸URL'].astype(str) != "") &
                (self.df['C_URL'].astype(str) != "")
            ][['D_è¢«ãƒªãƒ³ã‚¯å…ƒãƒšãƒ¼ã‚¸ã‚¿ã‚¤ãƒˆãƒ«', 'E_è¢«ãƒªãƒ³ã‚¯å…ƒãƒšãƒ¼ã‚¸URL',
               'B_ãƒšãƒ¼ã‚¸ã‚¿ã‚¤ãƒˆãƒ«', 'C_URL']].copy()

            def in_site(u: str) -> bool:
                try:
                    d = urlparse(u).netloc.lower()
                    if d.startswith("www."): d = d[4:]
                    return (not self.site_domain) or (d == self.site_domain) or d.endswith("." + self.site_domain)
                except Exception:
                    return True
            edges_df = edges_df[edges_df['E_è¢«ãƒªãƒ³ã‚¯å…ƒãƒšãƒ¼ã‚¸URL'].apply(in_site) & edges_df['C_URL'].apply(in_site)]
            if edges_df.empty:
                messagebox.showinfo("æƒ…å ±", "æç”»å¯¾è±¡ã‚¨ãƒƒã‚¸ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
                return

            in_counts = edges_df.groupby('C_URL').size().sort_values(ascending=False)

            TOP_N = 40  # é‡ã„å ´åˆã¯ 30 ãªã©ã«ä¸‹ã’ã¦OK
            top_targets = set(in_counts.head(TOP_N).index)

            sub = edges_df[edges_df['C_URL'].isin(top_targets)].copy()

            agg = sub.groupby(['E_è¢«ãƒªãƒ³ã‚¯å…ƒãƒšãƒ¼ã‚¸URL', 'C_URL']).size().reset_index(name='weight')

            url2title = {}
            for _, r in self.df[['B_ãƒšãƒ¼ã‚¸ã‚¿ã‚¤ãƒˆãƒ«','C_URL']].drop_duplicates().iterrows():
                if r['C_URL']:
                    url2title[r['C_URL']] = r['B_ãƒšãƒ¼ã‚¸ã‚¿ã‚¤ãƒˆãƒ«']
            for _, r in self.df[['D_è¢«ãƒªãƒ³ã‚¯å…ƒãƒšãƒ¼ã‚¸ã‚¿ã‚¤ãƒˆãƒ«','E_è¢«ãƒªãƒ³ã‚¯å…ƒãƒšãƒ¼ã‚¸URL']].drop_duplicates().iterrows():
                if r['E_è¢«ãƒªãƒ³ã‚¯å…ƒãƒšãƒ¼ã‚¸URL']:
                    url2title.setdefault(r['E_è¢«ãƒªãƒ³ã‚¯å…ƒãƒšãƒ¼ã‚¸URL'], r['D_è¢«ãƒªãƒ³ã‚¯å…ƒãƒšãƒ¼ã‚¸ã‚¿ã‚¤ãƒˆãƒ«'])

            def short_label(u: str, n=24) -> str:
                t = str(url2title.get(u, u))
                return (t[:n] + "â€¦") if len(t) > n else t

            # PyVisãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®ä½œæˆ - ã“ã“ãŒä¿®æ­£éƒ¨åˆ†
            net = Network(
                height="800px", 
                width="100%", 
                directed=True, 
                bgcolor="#ffffff",
                font_color="black"
            )
            
            # ç‰©ç†ã‚¨ãƒ³ã‚¸ãƒ³ã®è¨­å®š
            net.barnes_hut(
                gravity=-8000,
                central_gravity=0.3,
                spring_length=160,
                spring_strength=0.03,
                damping=0.12,
                overlap=0.1
            )

            nodes = set(agg['E_è¢«ãƒªãƒ³ã‚¯å…ƒãƒšãƒ¼ã‚¸URL']).union(set(agg['C_URL']))
            
            def node_size(u: str) -> int:
                s = int(in_counts.get(u, 0))
                return max(12, min(48, int(12 + math.log2(s + 1) * 8)))

            # ãƒãƒ¼ãƒ‰ã‚’è¿½åŠ 
            for u in nodes:
                net.add_node(
                    u,
                    label=short_label(u),
                    title=f"{url2title.get(u, u)}<br>{u}",
                    size=node_size(u)
                )

            # ã‚¨ãƒƒã‚¸ã‚’è¿½åŠ 
            for _, r in agg.iterrows():
                src = r['E_è¢«ãƒªãƒ³ã‚¯å…ƒãƒšãƒ¼ã‚¸URL']
                dst = r['C_URL']
                w   = int(r['weight'])
                net.add_edge(src, dst, width=min(w, 8))  # widthåˆ¶é™ã§è¦–èªæ€§å‘ä¸Š

            # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã®è¨­å®š
            out_dir = Path.cwd()/"network_exports"
            out_dir.mkdir(exist_ok=True)
            out_html = out_dir / f"interactive_network_{datetime.now().strftime('%Y%m%d_%H%M%S')}.html"

            # HTMLãƒ•ã‚¡ã‚¤ãƒ«ã®ç”Ÿæˆ - ä¿®æ­£ç‰ˆ
            try:
                # save_graphã®ä»£ã‚ã‚Šã«writeãƒ¡ã‚½ãƒƒãƒ‰ã‚’ä½¿ç”¨
                net.save_graph(str(out_html))
                logger.info(f"Network graph saved to: {out_html}")
                
                # è‡ªå‹•ã‚ªãƒ¼ãƒ—ãƒ³ã®å‡¦ç†
                if self.auto_open.get():
                    self._maybe_open(out_html)
                
                self.last_html = out_html
                
                self._print(
                    f"\nã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’ç”Ÿæˆã—ã¾ã—ãŸ: {out_html}\n"
                    f"ï¼ˆãƒãƒ¼ãƒ‰={len(nodes)} / ã‚¨ãƒƒã‚¸={len(agg)} / ä¸Šä½ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ={len(top_targets)} / "
                    f"è‡ªå‹•ã‚ªãƒ¼ãƒ—ãƒ³: {'ON' if self.auto_open.get() else 'OFF'}ï¼‰\n"
                    "â€» é‡ã„ã¨æ„Ÿã˜ãŸã‚‰ TOP_N ã‚’ 30 ãªã©ã«ä¸‹ã’ã¦ãã ã•ã„ã€‚\n"
                    "â€» ã•ã‚‰ã«è»½ãã™ã‚‹ã«ã¯ weight=1 ã®ã‚¨ãƒƒã‚¸ã‚’é™¤å¤–ã™ã‚‹ç­‰ã®èª¿æ•´ã‚‚æœ‰åŠ¹ã§ã™ã€‚\n"
                )
                
            except Exception as pyvis_error:
                logger.exception("PyVis network generation failed")
                
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ç°¡å˜ãªHTMLãƒ†ãƒ¼ãƒ–ãƒ«å½¢å¼ã§å‡ºåŠ›
                self._print(f"\nPyVisæç”»ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯è¡¨ç¤ºã‚’ç”Ÿæˆã—ã¾ã™ã€‚\nã‚¨ãƒ©ãƒ¼: {pyvis_error}\n")
                
                rank = in_counts.head(TOP_N).items()
                fallback_html = [
                    "<!doctype html><meta charset='utf-8'>",
                    f"<title>Network Analysis - {self.site_name} (fallback)</title>",
                    "<style>body{font-family: Arial, 'Yu Gothic', Meiryo, sans-serif; padding:16px;} table{border-collapse:collapse; width:100%;} th,td{border:1px solid #ddd; padding:8px;} th{background:#f7f7f7;} a{color:#1565c0; text-decoration:none;} a:hover{text-decoration:underline;}</style>",
                    f"<h2>ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯åˆ†æçµæœ - {self.site_name}</h2>",
                    "<p>PyVisæç”»ã«å¤±æ•—ã—ãŸãŸã‚ã€ä¸Šä½ãƒšãƒ¼ã‚¸ã®ä¸€è¦§ã‚’è¡¨ç¤ºã—ã¦ã„ã¾ã™ã€‚</p>",
                    "<table><thead><tr><th>é †ä½</th><th>ãƒšãƒ¼ã‚¸ã‚¿ã‚¤ãƒˆãƒ«</th><th>URL</th><th>è¢«ãƒªãƒ³ã‚¯æ•°</th></tr></thead><tbody>"
                ]
                
                for i, (url, count) in enumerate(rank, 1):
                    title = url2title.get(url, url)
                    title_escaped = title.replace("&", "&amp;").replace("<", "&lt;").replace(">", "&gt;")
                    fallback_html.append(
                        f"<tr><td>{i}</td><td>{title_escaped}</td>"
                        f"<td><a href='{url}' target='_blank' rel='noopener'>{url}</a></td>"
                        f"<td>{count}</td></tr>"
                    )
                
                fallback_html.append("</tbody></table>")
                
                with open(out_html, "w", encoding="utf-8") as f:
                    f.write("\n".join(fallback_html))
                
                self.last_html = out_html
                self._print(f"\nãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯è¡¨ç¤ºã‚’ç”Ÿæˆã—ã¾ã—ãŸ: {out_html}\n")
                self._maybe_open(out_html)

        except Exception as e:
            logger.exception("show_interactive_network failed")
            messagebox.showerror("æç”»ã‚¨ãƒ©ãƒ¼", f"ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å›³ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ:\n{e}")
            self._print(f"\n[è‡´å‘½çš„ã‚¨ãƒ©ãƒ¼] {e}\n")

    # ------------ ç›´è¿‘HTMLã‚’é–‹ã/ä¿å­˜ ------------
    def open_last_html(self):
        from tkinter import messagebox
        if not self.last_html or not Path(self.last_html).exists():
            messagebox.showinfo("æƒ…å ±", "ç›´è¿‘ã®HTMLãƒ¬ãƒãƒ¼ãƒˆãŒã‚ã‚Šã¾ã›ã‚“ã€‚å…ˆã«åˆ†æã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
            return
        try:
            if os.name == "nt": os.startfile(self.last_html)
            else: webbrowser.open(Path(self.last_html).as_posix())
        except Exception:
            webbrowser.open(Path(self.last_html).as_posix())

    def save_last_html(self):
        from tkinter import filedialog, messagebox
        if not self.last_html or not Path(self.last_html).exists():
            messagebox.showinfo("æƒ…å ±", "ç›´è¿‘ã®HTMLãƒ¬ãƒãƒ¼ãƒˆãŒã‚ã‚Šã¾ã›ã‚“ã€‚å…ˆã«åˆ†æã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
            return
        try:
            dest = filedialog.asksaveasfilename(defaultextension=".html",
                                                filetypes=[("HTML files","*.html")],
                                                initialfile=os.path.basename(self.last_html))
            if not dest: return
            with open(self.last_html, "r", encoding="utf-8") as f: content = f.read()
            with open(dest, "w", encoding="utf-8") as f: f.write(content)
            messagebox.showinfo("ä¿å­˜", f"ä¿å­˜ã—ã¾ã—ãŸ: {dest}")
        except Exception:
            logger.exception("save_last_html failed")

    # ------------ Run ------------
    def run(self):
        self.root.mainloop()

def main():
    app = App()
    app.run()

if __name__ == "__main__":
    main()
